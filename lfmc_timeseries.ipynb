{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this within dea-notebooks/ on the VDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Scripts/') # i.e. dea-notebooks/Scripts/\n",
    "\n",
    "import datacube\n",
    "from datacube.utils import geometry\n",
    "from dea_datahandling import load_ard\n",
    "import rasterio.crs\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentinel_timeseries(df, file_path:str, begin:str = None, end:str = None):\n",
    "    \n",
    "    \"\"\"This function takes area of interest from geometry of a geopandas dataframe, \n",
    "    and saves a xarray dataset of Fuel Moisture Content.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    df - gpd.Dataframe, shapefile or other file opened in geopandas\n",
    "    begin - str, date of beginning of timeseries in format YYYY-MM-DD)\n",
    "    end - str, date of ending of timeseries in format YYYY-MM-DD)\n",
    "    file_path - str, absolute filepath to save file to e.g. '/g/data/..'\n",
    "    \"\"\"\n",
    "\n",
    "    if type(begin) is str:\n",
    "        None\n",
    "    else:\n",
    "        begin = '2015-01-01'\n",
    "        \n",
    "    if type(end) is str:\n",
    "        None\n",
    "    else:\n",
    "        end = date.today()\n",
    "\n",
    "    # get bounds and crs from dataframe (minx, miny, maxx, maxy)\n",
    "    bounds = df.geometry.bounds\n",
    "    crs = df.crs.to_epsg()\n",
    "    \n",
    "    dc = datacube.Datacube(app='fmc')\n",
    "    \n",
    "    # start loop through df of bounds, updating query with y and x points\n",
    "    for idx_name,series in bounds.iterrows():\n",
    "        print(f'Analysing {idx_name} data from {begin} to {end}')\n",
    "        minx,miny,maxx,maxy = series\n",
    "\n",
    "        query = {\n",
    "            'y': (miny,maxy),\n",
    "            'x': (minx,maxx),\n",
    "            'crs': f'EPSG:{crs}',\n",
    "            'output_crs': 'EPSG:3577',\n",
    "            'resolution': (-25, 25),        \n",
    "            'time': (begin,end),\n",
    "            'measurements': [\"nbar_blue\",\"nbar_green\",\"nbar_red\",\n",
    "                             \"nbart_red_edge_1\",\"nbart_red_edge_2\",\"nbart_red_edge_3\",\n",
    "                             \"nbar_nir_1\",\"nbar_nir_2\",\"nbar_swir_2\",\"nbar_swir_3\",'fmask'\n",
    "                            ],\n",
    "            'group_by':'solar_day',\n",
    "            'min_gooddata':0.5\n",
    "        }\n",
    "\n",
    "        s2_ds = load_ard(dc=dc,\n",
    "                     products=['s2a_ard_granule'],\n",
    "                     **query)\n",
    "\n",
    "    ## start FMC model\n",
    "\n",
    "        refl = s2_ds[[\"nbar_green\",\"nbar_red\",\"nbart_red_edge_1\",\"nbart_red_edge_2\",\"nbart_red_edge_3\",\n",
    "                 \"nbar_nir_1\",\"nbar_nir_2\",\"nbar_swir_2\",\"nbar_swir_3\"]].to_array().values/10000\n",
    "\n",
    "        ndvi=((s2_ds.nbar_nir_1-s2_ds.nbar_red)/(s2_ds.nbar_nir_1+s2_ds.nbar_red)).values \n",
    "        s2_ds['ndii']=((s2_ds.nbar_nir_1-s2_ds.nbar_swir_2)/(s2_ds.nbar_nir_1+s2_ds.nbar_swir_2))\n",
    "        ndii=s2_ds.ndii.values\n",
    "\n",
    "        refl = np.concatenate([refl,ndii[None,:,:]], axis=0)\n",
    "\n",
    "        print(f'Shape of reflectance; {refl.shape}, and NDVI data; {ndvi.shape}')\n",
    "\n",
    "\n",
    "        ds = xr.open_dataset(\"http://dapds00.nci.org.au/thredds/dodsC/ub8/au/LandCover/OzWALD_LC/VegH_2007-2010_mosaic_AustAlb_25m.nc\")\n",
    "        vegh = ds.VegH.sel(x=s2_ds.x, y=s2_ds.y)\n",
    "\n",
    "        ds = xr.open_dataset(\"http://dapds00.nci.org.au/thredds/dodsC/ub8/au/LandCover/OzWALD_LC/WCF_2018_mosaic_AustAlb_25m.nc#fillmismatch\")\n",
    "        wcf = ds.WCF.sel(x=s2_ds.x, y=s2_ds.y)\n",
    "\n",
    "        \"\"\"\n",
    "        grass = (wcf<10)*(vegh<2)*(vegh!=0)*1\n",
    "        shrub = (wcf>=10)*(vegh<2)*(vegh!=0)*2\n",
    "        sav_2 = (wcf>=10)*(wcf<20)*(vegh>=2)*3\n",
    "        sav_1 = (wcf>=20)*(wcf<30)*(vegh>=2)*4\n",
    "        forest = (wcf>=30)*(vegh>=2)*5\n",
    "        \"\"\"\n",
    "\n",
    "        # Original classes with savanah merged into shrub\n",
    "        grass = (wcf<10)*(vegh<2)*(vegh!=0)*1\n",
    "        shrub = (wcf>=10)*(vegh<2)*(vegh!=0)*2\n",
    "        sav_2 = (wcf>=10)*(wcf<20)*(vegh>=2)*2\n",
    "        sav_1 = (wcf>=20)*(wcf<30)*(vegh>=2)*2\n",
    "        forest = (wcf>=30)*(vegh>=2)*3\n",
    "\n",
    "        mask = shrub+grass+sav_1+sav_2+forest\n",
    "        mask = mask.values.T\n",
    "\n",
    "\n",
    "        # read Look Up Table from file\n",
    "        df = pd.read_csv(file_path+'LUT_S2.csv', index_col='ID')\n",
    "        #NDII=nbar_nir_1-nbar_swir_2/nbar_nir_1+nbar_swir_2\n",
    "        df = df.drop(columns=['lai','soil','n','443','490','1375','945'])\n",
    "        df.columns = ['fmc','landcover','green','red','red_edge1','red_edge2','red_edge3','nir1','nir2','swir2','swir3']\n",
    "        # df[df.landcover=='forest'].shape, df[df.landcover=='shrub'].shape, df[df.landcover=='grass'].shape\n",
    "        df['ndii'] = (df['nir1']-df['swir2'])/(df['nir1']+df['swir2'])\n",
    "\n",
    "        canvas1 = np.ones(ndvi.shape, dtype=np.float32) * np.nan\n",
    "        top_n = 40\n",
    "\n",
    "        lut_map = {\n",
    "            1: df[df.landcover == \"grass\"][\n",
    "                [\n",
    "                    \"fmc\",\n",
    "                    \"green\",\n",
    "                    \"red\",\n",
    "                    \"red_edge1\",\n",
    "                    \"red_edge2\",\n",
    "                    \"red_edge3\",\n",
    "                    \"nir1\",\n",
    "                    \"nir2\",\n",
    "                    \"swir2\",\n",
    "                    \"swir3\",\n",
    "                    \"ndii\",\n",
    "                ]\n",
    "            ].values,\n",
    "            2: df[df.landcover == \"shrub\"][\n",
    "                [\n",
    "                    \"fmc\",\n",
    "                    \"green\",\n",
    "                    \"red\",\n",
    "                    \"red_edge1\",\n",
    "                    \"red_edge2\",\n",
    "                    \"red_edge3\",\n",
    "                    \"nir1\",\n",
    "                    \"nir2\",\n",
    "                    \"swir2\",\n",
    "                    \"swir3\",\n",
    "                    \"ndii\",\n",
    "                ]\n",
    "            ].values,\n",
    "            3: df[df.landcover == \"forest\"][\n",
    "                [\n",
    "                    \"fmc\",\n",
    "                    \"green\",\n",
    "                    \"red\",\n",
    "                    \"red_edge1\",\n",
    "                    \"red_edge2\",\n",
    "                    \"red_edge3\",\n",
    "                    \"nir1\",\n",
    "                    \"nir2\",\n",
    "                    \"swir2\",\n",
    "                    \"swir3\",\n",
    "                    \"ndii\",\n",
    "                ]\n",
    "            ].values,\n",
    "        }\n",
    "\n",
    "        # Add the squares of the LUT entries to speed up computation inside loop\n",
    "        lut_map[4] = np.einsum(\"ij,ij->i\", lut_map[1][:, 1:], lut_map[1][:, 1:]) ** 0.5\n",
    "        lut_map[5] = np.einsum(\"ij,ij->i\", lut_map[2][:, 1:], lut_map[2][:, 1:]) ** 0.5\n",
    "        lut_map[6] = np.einsum(\"ij,ij->i\", lut_map[3][:, 1:], lut_map[3][:, 1:]) ** 0.5\n",
    "\n",
    "        for t in range(ndvi.shape[0]):\n",
    "\n",
    "            for j in range(mask.shape[0]):\n",
    "\n",
    "                for i in range(mask.shape[1]):\n",
    "                    x = refl[:,t, j, i]\n",
    "                    m = mask[j, i]\n",
    "\n",
    "                    if m == 0 or ndvi[t, j, i] < 0.15:\n",
    "                        continue\n",
    "\n",
    "                    θ = -1 * (\n",
    "                        np.einsum(\"ij,j->i\", lut_map[m][:, 1:], x)\n",
    "                        / (np.einsum(\"i,i->\", x, x) ** 0.5 * lut_map[m + 3])\n",
    "                    )\n",
    "\n",
    "                    idxs = np.argpartition(θ, top_n)[:top_n]\n",
    "                    canvas1[t, j, i] = np.median(lut_map[m][idxs, 0])\n",
    "\n",
    "        s2_ds['FMC'] = (['time','y','x'], canvas1)\n",
    "        s2_ds['FMC'] = s2_ds['FMC'] * s2_ds.fmask.where(s2_ds.fmask==1,np.NaN)\n",
    "        # drop variables not to be saved in netcdf\n",
    "        s2_ds = s2_ds.drop_vars(['nbar_blue','nbar_green','nbar_red','nbart_red_edge_1','nbart_red_edge_2',\n",
    "                       'nbart_red_edge_3','nbar_nir_1','nbar_nir_2','nbar_swir_2','nbar_swir_3','ndii','fmask'])\n",
    "\n",
    "        for variable in s2_ds.variables.values():\n",
    "            variable.attrs = {}\n",
    "        s2_ds.attrs['units'] = '% dry matter'\n",
    "            \n",
    "        s2_ds.to_netcdf(file_path+idx_name+'.nc',mode='w')\n",
    "        \n",
    "        print('------------')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path names, load the shapefile, modify shapefile dataframe\n",
    "\n",
    "# path_file = '/g/data/..' # change this to accessible storage\n",
    "# shapefile_path = 'areas_interest.shp'\n",
    "# df = gpd.read_file(path_file.join(shapefile_path))\n",
    "# df.set_index('df column name of site names', inplace=True) # used to name the netcdf files\n",
    "# df.crs() # check to see if dataframe has a coordinate reference system and is appropriate, otherwise df.set_crs(epsg=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set path names, load the shapefile, modify shapefile dataframe\n",
    "\n",
    "path_file = '/g/data/xc0/user/IvanK/' # change this to accessible storage\n",
    "shapefile_path = 'sites/2plots.shp'\n",
    "df = gpd.read_file(shapefile_path)\n",
    "df.set_index('plot_name', inplace=True) # used to name the netcdf files\n",
    "df.crs # check to see if dataframe has a coordinate reference system and is appropriate, otherwise df.set_crs(epsg=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing Plot2_Lois data from 2019 to 2020\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 45 out of 108 time steps with at least 50.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 45 time steps\n",
      "Shape of reflectance; (10, 45, 1, 1), and NDVI data; (45, 1, 1)\n",
      "------------\n",
      "Analysing Plot1_Lois data from 2019 to 2020\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 77 out of 139 time steps with at least 50.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 77 time steps\n",
      "Shape of reflectance; (10, 77, 1, 1), and NDVI data; (77, 1, 1)\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "sentinel_timeseries(df, path_file,'2019', '2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
